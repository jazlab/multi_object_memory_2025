"""Run this script to generate and save PSTH plots for every unit.

Usage:
$ python3 run_triangle.py

This generates a PSTH plot for each unit and saves it to
"../cache/phys_processing/psths/$SUBJECT/$SESSION/$PROBE/$QUALITY/$UNIT.pdf"

This script requires the following cached data:
- Firing rates for each unit in the delay phase, saved in
  `../../cache/phys_processing/spikes_to_trials/spikes_per_trial`. This
  can be generated by running the script
  `../spikes_to_trials/run_spikes_per_trial.py`.
- Behavior data for the triangle task, saved in
  `../../cache/behavior/triangle.csv`. This can be generated by running the
  script `../../behavior_processing/run_cache_data.py`.
"""

import pickle
from pathlib import Path

import constants
import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt

_SPIKE_COUNTS_DATA_DIR = Path(
    "../../cache/phys_processing/spikes_to_trials/spikes_per_trial"
)
_WRITE_DIR = Path("../../cache/phys_processing/psths")
_BEHAVIOR_CACHE_PATH_TRIANGLE = Path("../../cache/behavior/triangle.csv")
_PALETTE = {
    (0,): (1, 0, 0),
    (1,): (0, 1, 0),
    (2,): (0, 0, 1),
    (0, 1): (0.7, 0.7, 0),
    (0, 2): (0.7, 0, 0.7),
    (1, 2): (0, 0.7, 0.7),
    (0, 1, 2): (0.5, 0.5, 0.5),
}
_DASHES = {
    0: (1.0, 0.0),
    1: (1.0, 1.0),
    2: (3.0, 1.5),
}
# Time window for stimulus phase in ms
_STIM_TIME_WINDOW = (0, 2500)
# Time window for cue phase in ms, relative to cue onset
_CUE_TIME_WINDOW = (0, 500)


def _smooth(
    spike_count: np.ndarray,
    half_window_size_ms: int = 50,
) -> np.ndarray:
    """Smooth spike count using a triangular kernel.

    Args:
        spike_count: Spike count vector to smooth.
        half_window_size_ms: Half window size in milliseconds for smoothing.

    Returns:
        smooth_spike_count: Smoothed spike count vector.
    """
    half_window_bins = int(
        half_window_size_ms / (1000 * constants.BIN_SIZE_SECONDS)
    )
    linspace = np.linspace(0, 1, 1 + half_window_bins)[1:]
    kernel = np.concatenate([linspace[:-1], linspace[::-1]])
    kernel /= kernel.sum()
    conv_spike_count = np.convolve(spike_count, kernel, mode="same")
    conv_ones = np.convolve(np.ones_like(spike_count), kernel, mode="same")
    smooth_spike_count = conv_spike_count / conv_ones
    return smooth_spike_count


def generate_psth(
    spike_counts: np.ndarray,
    trials: pd.Series,
    session_behavior: pd.DataFrame,
    n_boot=100,
) -> plt.Figure:
    """Generate PSTH plot for a unit.

    Args:
        spike_counts: Binned spike train for each trial.
        trials: List of trial numbers corresponding to the trials in
            spike_counts.
        session_behavior: DataFrame with session behavior data.
        n_boot: Number of bootstrap samples for error bars.

    Returns:
        fig: Figure object containing the PSTH plot.
    """
    if len(spike_counts) != len(trials):
        raise ValueError(
            f"Length of spike_counts ({len(spike_counts)}) must match length "
            f"of trials ({len(trials)})"
        )

    # Create dataframe with spike counts
    df_dict = {
        "time": [],
        "num_objects": [],
        "locations": [],
        "target_location": [],
        "firing_rate": [],
    }
    delay_times = []
    cue_times = []
    response_times = []
    for trial_num, spike_count in zip(trials, spike_counts):
        trial = session_behavior.loc[
            session_behavior["trial_num"] == trial_num
        ]
        if not trial.on_triangle.values[0]:
            continue
        num_objects = trial["num_objects"].values[0]

        # Get delay, cue, and response times
        stim_time = trial.time_stimulus_onset.values[0]
        delay_times.append(trial.time_delay_onset.values[0] - stim_time)
        cue_times.append(trial.time_cue_onset.values[0] - stim_time)
        response_times.append(trial.time_response_onset.values[0] - stim_time)

        # Get target location
        target_ind = trial["target_object_index"].values[0]
        target_location = int(trial[f"object_{target_ind}_location"].values[0])

        # Get object locations
        obj_locations = tuple(
            sorted(
                [
                    int(trial[f"object_{i}_location"].values[0])
                    for i in range(num_objects)
                ]
            )
        )

        # Smooth spike_count
        spike_count = _smooth(spike_count)

        # Update df_dict
        time = 1000 * constants.BIN_SIZE_SECONDS * np.arange(len(spike_count))
        df_dict["time"].extend(time - 1000 * constants.LEAD_IN_SECONDS)
        df_dict["num_objects"].extend([num_objects] * len(time))
        df_dict["locations"].extend([obj_locations] * len(time))
        df_dict["target_location"].extend([target_location] * len(time))
        bins_per_second = 1 / constants.BIN_SIZE_SECONDS
        df_dict["firing_rate"].extend(spike_count * bins_per_second)

    df = pd.DataFrame(df_dict)

    # Get mean delay, cue, and response times
    mean_delay_time = 1000 * np.mean(delay_times)
    mean_cue_time = 1000 * np.mean(cue_times)
    mean_response_time = 1000 * np.mean(response_times)
    mean_phase_times = [mean_delay_time, mean_cue_time, mean_response_time]

    fig, axes = plt.subplots(4, 2, figsize=(12, 12), width_ratios=(3.2, 1))
    for num_objects, ax_row in zip([1, 2, 3, None], axes):
        if num_objects is None:
            tmp_df = df
        else:
            tmp_df = df.loc[df["num_objects"] == num_objects]
        df_stim = tmp_df.loc[
            (tmp_df["time"] >= _STIM_TIME_WINDOW[0])
            & (tmp_df["time"] < _STIM_TIME_WINDOW[1])
        ]
        df_cue = tmp_df.loc[
            (tmp_df["time"] >= mean_cue_time + _CUE_TIME_WINDOW[0])
            & (tmp_df["time"] < mean_cue_time + _CUE_TIME_WINDOW[1])
        ]

        # Plot full trial
        ax_0 = ax_row[0]
        plot = sns.lineplot(
            ax=ax_0,
            data=df_stim,
            x="time",
            y="firing_rate",
            hue="locations",
            palette=_PALETTE,
            legend=False,
            n_boot=n_boot,
        )
        ymin, ymax = plot.get_ylim()
        ax_0.vlines(
            x=mean_phase_times,
            ymin=ymin,
            ymax=ymax,
            colors="k",
            linestyles="dashed",
        )
        n_obj_title = num_objects if num_objects is not None else "all"
        ax_0.set_title(f"Full Trial, {n_obj_title} Objects", fontsize=12)

        # Plot cue and response phases
        ax_1 = ax_row[1]
        plot = sns.lineplot(
            ax=ax_1,
            data=df_cue,
            x="time",
            y="firing_rate",
            hue="locations",
            style="target_location",
            palette=_PALETTE,
            dashes=_DASHES,
            legend=True,
            n_boot=n_boot,
        )
        ymin, ymax = plot.get_ylim()
        ax_1.vlines(
            x=[mean_response_time],
            ymin=ymin,
            ymax=ymax,
            colors="k",
            linestyles="dashed",
        )
        ax_1.set_title(f"Post-Cue, {n_obj_title} Objects", fontsize=12)
        ax_1.legend(bbox_to_anchor=(1.8, 1), borderaxespad=0, fontsize=8)

    for ax in axes.flatten():
        ax.set_xlabel("Time after stimulus (ms)", fontsize=10)
        ax.set_ylabel("Firing rate (Hz)", fontsize=10)

    return fig


def generate_psths(
    quality_dir: Path, session_behavior: pd.DataFrame, write_dir: Path
) -> None:
    """Generate and save PSTH plots for each unit in a quality directory.

    Args:
        quality_dir: Path to the directory containing spike counts and trials.
        session_behavior: DataFrame with session behavior data.
        write_dir: Directory to save the generated PSTH plots.
    """
    unit_count = 0
    num_units = len(list(quality_dir.iterdir())) // 2
    for spike_counts_file in sorted(quality_dir.iterdir()):
        if "spike_counts" not in spike_counts_file.name:
            continue
        trials_file = spike_counts_file.with_name(
            spike_counts_file.name.replace("spike_counts", "trials")
        )
        unit = spike_counts_file.name.split("_")[0]

        # Print progress if necessary
        if unit_count % 20 == 0:
            print(f"Processing unit {unit_count} / {num_units}")
        unit_count += 1

        # Load spike counts and trials
        spike_counts = pickle.load(open(spike_counts_file, "rb"))
        trials = pickle.load(open(trials_file, "rb"))

        # Generate figure
        fig = generate_psth(spike_counts, trials, session_behavior)
        title = f"Unit {unit}, {spike_counts_file.parent.name}"
        fig.suptitle(title)
        plt.tight_layout()
        fig.subplots_adjust(wspace=0.2, hspace=0.4)

        # Save figure
        fig.savefig(write_dir / f"{unit}.pdf")
        plt.close(fig)


def main():
    """Generate and save unit summary plots."""
    # Load behavior data
    triangle_behavior = pd.read_csv(_BEHAVIOR_CACHE_PATH_TRIANGLE)

    # Append each session to the dataframe
    for subject_dir in sorted(_SPIKE_COUNTS_DATA_DIR.iterdir()):
        subject = subject_dir.name
        if subject.startswith("."):
            continue
        print(f"\nProcessing {subject}\n")
        for session_dir in sorted(subject_dir.iterdir()):
            session = session_dir.name
            if session.startswith("."):
                continue
            print(f"\nProcessing {session}\n")

            # Load behavior data for this session
            session_behavior = triangle_behavior[
                (triangle_behavior["subject"] == subject)
                & (triangle_behavior["session"] == session)
            ]
            if len(session_behavior) == 0:
                print(f"No triangle data found for {subject} {session}")
                continue
            print(f"Number of trials = {len(session_behavior)}")

            # Iterate through units and generate PSTH plots
            for probe_dir in sorted(session_dir.iterdir()):
                probe = probe_dir.name
                if probe.startswith("."):
                    continue
                print(f"\nProcessing {probe}\n")

                for quality_dir in sorted(probe_dir.iterdir()):
                    quality = quality_dir.name
                    if quality.startswith("."):
                        continue
                    if quality != "good":
                        continue
                    print(f"\nProcessing {quality}\n")

                    write_dir = (
                        _WRITE_DIR / subject / session / probe / quality
                    )
                    write_dir.mkdir(parents=True, exist_ok=True)
                    generate_psths(quality_dir, session_behavior, write_dir)


if __name__ == "__main__":
    main()
