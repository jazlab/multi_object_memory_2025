{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to replay trials with neural activity and save as an mp4 with audio.\n",
    "\n",
    "This notebook will generate an mp4 in `./videos_with_neurons/`. This video will\n",
    "render a sequence of trials as the monkey sees it, except the monkey's gaze\n",
    "position is rendered post-hoc as a green cross. It will also display the trial\n",
    "phase on top and the spike times of three neurons on the bottom. Audio will\n",
    "contain claps for spikes from these neurons, with each neuron having a different\n",
    "pitch.\n",
    "\n",
    "By default, this notebook runs on a session included in our OSF cache. If you\n",
    "would like to run this notebook on trials from other sessions, you must first\n",
    "download the behavior and spike sorting dandi files for that session by\n",
    "navigating to the root directory (`../..`) and running\n",
    "```\n",
    "$ python3 download_dandi_data.py --subject=Perle --session=$your_session\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports.\"\"\"\n",
    "\n",
    "import ast\n",
    "from moviepy import CompositeVideoClip, AudioFileClip, CompositeAudioClip, ImageSequenceClip\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pynwb import NWBHDF5IO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import task_state as task_state_lib\n",
    "import renderer as renderer_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Units.\"\"\"\n",
    "\n",
    "BEHAVIOR_DATA_DIR = Path(\"../cache/dandi_data/behavior\")\n",
    "NEURAL_DATA_DIR = Path(\"../cache/dandi_data/spikesorting\")\n",
    "WRITE_DIR = Path(\"./videos_with_neurons\")\n",
    "WRITE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "SUBJECT = \"Perle\"\n",
    "SESSION = \"2022-05-31\"\n",
    "UNIT_IDS = [93, 131, 115]\n",
    "TRIALS = [94, 187, 1287, 963, 187, 465, 1132, 1382, 698]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../cache/dandi_data/behavior/sub-Perle/sub-Perle_ses-2022-05-31_behavior+task.nwb\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load data.\"\"\"\n",
    "\n",
    "CLICK_SOUNDS = [\n",
    "    AudioFileClip(\"./resources/audio/click_0.mp3\").subclipped(0.06, 0.1),\n",
    "    AudioFileClip(\"./resources/audio/click_1.mp3\").subclipped(0.06, 0.1),\n",
    "    AudioFileClip(\"./resources/audio/click_2.mp3\").subclipped(0.06, 0.1),\n",
    "]\n",
    "FIRST_SPIKE_BUFFER = -2\n",
    "LAST_SPIKE_BUFFER = 2\n",
    "\n",
    "# Load behavior data\n",
    "behavior_nwb_file_path = BEHAVIOR_DATA_DIR / f\"sub-{SUBJECT}/sub-{SUBJECT}_ses-{SESSION}_behavior+task.nwb\"\n",
    "neural_nwb_file_path = NEURAL_DATA_DIR / f\"sub-{SUBJECT}/sub-{SUBJECT}_ses-{SESSION}_spikesorting.nwb\"\n",
    "\n",
    "# Load neural data\n",
    "spikesorting_read_io = NWBHDF5IO(neural_nwb_file_path, mode=\"r\", load_namespaces=True)\n",
    "spikesorting_nwbfile = spikesorting_read_io.read()\n",
    "ecephys = spikesorting_nwbfile.processing[\"ecephys\"]\n",
    "units = ecephys.data_interfaces[\"units\"]\n",
    "electrodes_df = spikesorting_nwbfile.electrodes.to_dataframe()\n",
    "\n",
    "# Read behavior data from nwb file\n",
    "with NWBHDF5IO(behavior_nwb_file_path, \"r\") as io:\n",
    "    print(f\"Processing {behavior_nwb_file_path}\")\n",
    "    nwbfile = io.read()\n",
    "    all_trials_df = nwbfile.trials.to_dataframe()\n",
    "    all_display_df = nwbfile.intervals['display'].to_dataframe()\n",
    "\n",
    "# Resolve identities\n",
    "all_trials_df[\"stimulus_object_identities\"] = all_trials_df.stimulus_object_identities.apply(\n",
    "    lambda x: ast.literal_eval(x))\n",
    "all_trials_df[\"num_objects\"] = all_trials_df.stimulus_object_identities.apply(lambda x: len(x))\n",
    "\n",
    "# Filter 3-object correct trials\n",
    "all_trials_df = all_trials_df[\n",
    "    (all_trials_df.num_objects == 3)\n",
    "    & (all_trials_df.broke_fixation == False)\n",
    "    & (all_trials_df.reward_duration > 0)\n",
    "]\n",
    "\n",
    "# Reset index\n",
    "all_trials_df[\"trial_id\"] = all_trials_df.index\n",
    "all_trials_df = all_trials_df.reset_index(drop=True)\n",
    "trial_ids = all_trials_df.trial_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building video videos_with_neurons/Perle_2022-05-31.mp4.\n",
      "MoviePy - Writing audio in Perle_2022-05-31TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video videos_with_neurons/Perle_2022-05-31.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready videos_with_neurons/Perle_2022-05-31.mp4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Make video.\"\"\"\n",
    "\n",
    "# Constants\n",
    "pixels_per_unit = 64\n",
    "top_pad = 16\n",
    "left_pad = 16\n",
    "start_t = -0.3\n",
    "end_t = 0.7\n",
    "start_pixel = 256\n",
    "end_pixel = 1024\n",
    "spike_y_pad = 8\n",
    "spike_height = 40\n",
    "spike_width = 4\n",
    "past_color = (128, 64, 0, 255)\n",
    "future_color = (255, 128, 0, 255)\n",
    "frames_between_trials = 20\n",
    "_SPEED = 0.5\n",
    "IMAGE_SIZE = 1024\n",
    "\n",
    "# def _render_task_phase(phase, height=64):\n",
    "def _render_task_phase(phase, height=128):\n",
    "    # Render text in buffer\n",
    "    # font = ImageFont.load_default(size=42)\n",
    "    font = ImageFont.load_default(size=84)\n",
    "    buffer = Image.new('RGBA', (IMAGE_SIZE, height), (0, 0, 0, 255))\n",
    "    draw = ImageDraw.Draw(buffer)\n",
    "    # capitalize phase\n",
    "    text = phase.capitalize()\n",
    "    # Draw text centered\n",
    "    text_width = draw.textlength(text, font=font)\n",
    "    text_height = font.size\n",
    "    left_pad = (IMAGE_SIZE - text_width) // 2\n",
    "    y = (height - text_height) // 2\n",
    "    # Draw text\n",
    "    draw.text((left_pad, y), text, fill=(255, 255, 255, 255), font=font)\n",
    "    # Convert to numpy array\n",
    "    buffer = np.array(buffer)[:, :, :3]\n",
    "    return buffer\n",
    "\n",
    "def _render_trial(trial_df, display_df):\n",
    "    \"\"\"Render trial.\"\"\"\n",
    "    # Get task state and renderer\n",
    "    stim_positions = ast.literal_eval(trial_df.stimulus_object_positions.values[0])\n",
    "    stim_identities = trial_df.stimulus_object_identities.values[0]\n",
    "    stim_target_str = trial_df.stimulus_object_target.values[0]\n",
    "    stim_target = stim_target_str[1:-1].split(\", \")\n",
    "    stim_target = [x == 'true' for x in stim_target]\n",
    "    task_state = task_state_lib.get_task_state(\n",
    "        stim_positions, stim_identities, stim_target)\n",
    "    for p in task_state['prey']:\n",
    "        p.opacity = 255\n",
    "    task_state['eye'][0].opacity = 255\n",
    "    background_indices = (0, 0)\n",
    "    renderer = renderer_lib.Renderer(image_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "    # Iterate through timesteps and render frames\n",
    "    frames = []\n",
    "    num_timesteps = len(display_df)\n",
    "    for timestep in range(num_timesteps):\n",
    "        fixation_cross_scale = display_df.loc[timestep, 'fixation_cross_scale']\n",
    "        eye_position = display_df.loc[timestep, 'closed_loop_eye_position']\n",
    "        task_phase = display_df.loc[timestep, 'task_phase']\n",
    "\n",
    "        # Modify state according to timestep\n",
    "        task_state['fixation'][0].scale = fixation_cross_scale\n",
    "        task_state['eye'][0].position = eye_position\n",
    "        task_state['fw'][0].position = eye_position\n",
    "        blank = False\n",
    "        if task_phase == 'fixation':\n",
    "            for p in task_state['prey']:\n",
    "                p.opacity = 0\n",
    "        elif task_phase == 'stimulus':\n",
    "            for p in task_state['prey']:\n",
    "                p.opacity = 255\n",
    "        elif task_phase == 'delay':\n",
    "            for p in task_state['prey']:\n",
    "                p.opacity = 0\n",
    "            blank = trial_df.delay_object_blanks.values[0]\n",
    "        elif task_phase == 'cue':\n",
    "            task_state['fixation'][0].opacity = 0\n",
    "            for p in task_state['prey']:\n",
    "                p.opacity = 0\n",
    "            task_state['cue'][0].opacity = 255\n",
    "            blank = trial_df.delay_object_blanks.values[0]\n",
    "        elif task_phase == 'response':\n",
    "            task_state['fixation'][0].opacity = 0\n",
    "            for p in task_state['prey']:\n",
    "                p.opacity = 0\n",
    "            task_state['cue'][0].opacity = 150\n",
    "            task_state['fw'][0].opacity = 255\n",
    "            blank = trial_df.delay_object_blanks.values[0]\n",
    "        elif task_phase == 'reveal':\n",
    "            task_state['fixation'][0].opacity = 0\n",
    "            for p in task_state['prey']:\n",
    "                p.opacity = 145\n",
    "            task_state['cue'][0].opacity = 150\n",
    "            task_state['fw'][0].opacity = 255\n",
    "        else:\n",
    "            raise ValueError(f'Unknown task_phase: {task_phase}')\n",
    "        \n",
    "        image = renderer(task_state, background_indices, blank=blank)\n",
    "        \n",
    "        # Add task phase text\n",
    "        task_phase_image = _render_task_phase(task_phase)\n",
    "        image = np.concatenate((task_phase_image, image), axis=0)\n",
    "        \n",
    "        # Append frame\n",
    "        frames.append(image)\n",
    "        \n",
    "    return frames\n",
    "\n",
    "# Get videos per trial\n",
    "video_per_trial = []\n",
    "for trial_index in TRIALS:\n",
    "    # Compute trial and display dataframes for the selected trial\n",
    "    trial_df = all_trials_df[all_trials_df.trial_id == trial_index]\n",
    "    trial_id = trial_df[\"trial_id\"]\n",
    "    display_df = all_display_df[\n",
    "        (all_display_df['start_time'] > trial_df['phase_stimulus_time'].values[0] - 0.25) &\n",
    "        (all_display_df['stop_time'] < trial_df['stop_time'].values[0])\n",
    "    ].reset_index(drop=True)\n",
    "    \n",
    "    # Get spike times per unit\n",
    "    first_frame_time = display_df.start_time.values[0]\n",
    "    last_frame_time = display_df.stop_time.values[-1]\n",
    "    spike_times_per_unit = []\n",
    "    for unit_id in UNIT_IDS:\n",
    "        spike_times = units.spike_times_index[unit_id]\n",
    "        spike_times_in_trial = spike_times[\n",
    "            (spike_times >= first_frame_time + FIRST_SPIKE_BUFFER) &\n",
    "            (spike_times <= last_frame_time + LAST_SPIKE_BUFFER)\n",
    "        ] - first_frame_time\n",
    "        frame_times = display_df.start_time.values - first_frame_time\n",
    "        spike_times_per_unit.append(spike_times_in_trial)\n",
    "        \n",
    "    # Get frames\n",
    "    frames = _render_trial(trial_df, display_df)\n",
    "    \n",
    "    # Render text in buffer\n",
    "    num_units = len(UNIT_IDS)\n",
    "    y_values = (top_pad + pixels_per_unit * np.arange(num_units)).astype(int)\n",
    "    font = ImageFont.load_default(size=40)\n",
    "    height = top_pad + pixels_per_unit * num_units\n",
    "    buffer = Image.new('RGBA', (frames[0].shape[1], height), (0, 0, 0, 255))\n",
    "    draw = ImageDraw.Draw(buffer)\n",
    "    for i, y in enumerate(y_values):\n",
    "        text = f\"Neuron {UNIT_IDS[i]}\"\n",
    "        draw.text((left_pad, y), text, fill=(255, 255, 255, 255), font=font)\n",
    "    buffer_array = np.array(buffer)\n",
    "\n",
    "    frames_with_spikes = []\n",
    "    for i, row in display_df.iterrows():\n",
    "        frame_time = row['start_time'] - first_frame_time\n",
    "        \n",
    "        buffer = np.copy(buffer_array)\n",
    "        \n",
    "        # Render present line\n",
    "        present_value = -start_t / (end_t - start_t)\n",
    "        present_pixel = int(start_pixel + (end_pixel - start_pixel) * present_value)\n",
    "        buffer[:, present_pixel:present_pixel + 1] = (128, 128, 128, 255)\n",
    "        \n",
    "        # Render spikes\n",
    "        for y, spike_times in zip(y_values, spike_times_per_unit):\n",
    "            spikes = spike_times[\n",
    "                (spike_times >= frame_time + start_t) &\n",
    "                (spike_times <= frame_time + end_t)\n",
    "            ]\n",
    "            past_labels = spikes < frame_time\n",
    "            spikes = (spikes - (frame_time + start_t)) / (end_t - start_t)\n",
    "            spike_pixels = (\n",
    "                start_pixel + (end_pixel - start_pixel) * spikes\n",
    "            ).astype(int)\n",
    "            for spike, past in zip(spike_pixels, past_labels):\n",
    "                color = past_color if past else future_color\n",
    "                buffer[y + spike_y_pad: y + spike_y_pad + spike_height, spike - spike_width: spike] = color\n",
    "                \n",
    "        # Append buffer to frame\n",
    "        frame = np.concatenate((frames[i], buffer[:, :, :3]), axis=0)\n",
    "        frames_with_spikes.append(frame)\n",
    "    \n",
    "    # Add more buffer\n",
    "    empty_frame = np.zeros_like(frames[0], dtype=np.uint8)\n",
    "    frame_with_buffer = np.concatenate([empty_frame, buffer_array[:, :, :3]], axis=0)\n",
    "    for _ in range(frames_between_trials):\n",
    "        frames_with_spikes.append(frame_with_buffer)\n",
    "        \n",
    "    # Make video\n",
    "    video_clip = ImageSequenceClip(frames_with_spikes, fps=int(_SPEED * 60))\n",
    "    audio_clips = []\n",
    "    for clip, spike_times in zip(CLICK_SOUNDS, spike_times_per_unit):\n",
    "        for t in spike_times:\n",
    "            if t < 0:\n",
    "                continue\n",
    "            if t > last_frame_time - first_frame_time:\n",
    "                continue\n",
    "            audio_clips.append(clip.with_start(t / _SPEED))\n",
    "    composite_audio = CompositeAudioClip(audio_clips)\n",
    "    video_clip.audio = composite_audio\n",
    "    \n",
    "    # Append video\n",
    "    video_per_trial.append(video_clip)\n",
    "    \n",
    "# Write the result\n",
    "clips = [video_per_trial[0]]\n",
    "for v in video_per_trial[1:]:\n",
    "    clips.append(v.with_start(clips[-1].end))\n",
    "\n",
    "composite = CompositeVideoClip(clips)\n",
    "write_path = WRITE_DIR / f\"{SUBJECT}_{SESSION}.mp4\"\n",
    "composite.write_videofile(write_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wm_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
