"""Run this script to compute and cache firing rates per phase.

Usage:
$ python3 run_firing_rates_per_phase.py

For this script to work, you need to have already run the spike counts script
"run_spikes_per_trial.py" to generate spike counts for each unit.

This computes a dataframe for each session with columns:
- probe
- quality
- unit
- trial
- firing_rate_stimulus
- firing_rate_delay

This dataframe is saved to a file
"../cache/phys_processing/spikes_to_trials/delay_phase_firing_rates/$SUBJECT/$SESSION/fr.csv"

This script requires the following cached data:
- Firing rates for each unit in the delay phase, saved in
  `../../cache/phys_processing/spikes_to_trials/spikes_per_trial`. This
  can be generated by running the script
  `../spikes_to_trials/run_spikes_per_trial.py`.
- Behavior data for the triangle and ring tasks, saved in
  `../../cache/behavior_processing/triangle.csv` and
  `../../cache/behavior_processing/ring.csv`. This can be generated by running
  the script `../../behavior_processing/run_cache_data.py`.

Note: By default, this script computes firing rates during the delay phase. To
compute firing rates during the stimulus phase instead, change the _PHASE
variable at the top of the script from "delay" to "stimulus".
"""

import pickle
from pathlib import Path

import constants
import numpy as np
import pandas as pd

_PHASE = "stimulus"
# _PHASE = "delay"

_SPIKE_COUNTS_DATA_DIR = Path(
    "../../cache/phys_processing/spikes_to_trials/spikes_per_trial"
)
_BEHAVIOR_CACHE_PATH_TRIANGLE = Path(
    "../../cache/behavior_processing/triangle.csv"
)
_BEHAVIOR_CACHE_PATH_RING = Path("../../cache/behavior_processing/ring.csv")
_WRITE_DIR = Path("../../cache/phys_processing/spikes_to_trials")
_WRITE_DIR = _WRITE_DIR / f"{_PHASE}_phase_firing_rates"


def _get_firing_rates(
    spike_counts: list[list], trials: list[int], session_behavior: pd.DataFrame
) -> list[float]:
    """Get firing rates.

    Args:
        spike_counts: Binned spike train for each trial.
        trials: List of trial numbers corresponding to the trials in
            spike_counts.
        session_behavior: DataFrame with session behavior data.

    Returns:
        fr_per_trial: List of mean firing rates for each trial.
    """

    # Get mean firing rate for each trial
    fr_per_trial = []
    for trial_num, spike_count in zip(trials, spike_counts):
        trial = session_behavior.loc[
            session_behavior["trial_num"] == trial_num
        ]
        trial_start_time = (
            trial.time_stimulus_onset.values[0] - constants.LEAD_IN_SECONDS
        )
        delay_time = trial.time_delay_onset.values[0] - trial_start_time
        cue_time = trial.time_cue_onset.values[0] - trial_start_time

        # Get start and end indices for firing rates
        if _PHASE == "stimulus":
            start_ind = int(
                constants.LEAD_IN_SECONDS / constants.BIN_SIZE_SECONDS
            )
            end_ind = int(delay_time / constants.BIN_SIZE_SECONDS)
        elif _PHASE == "delay":
            start_ind = int(delay_time / constants.BIN_SIZE_SECONDS)
            end_ind = int(cue_time / constants.BIN_SIZE_SECONDS)
        else:
            raise ValueError(f"Invalid phase {_PHASE}")

        # Append data
        bins_per_second = 1 / constants.BIN_SIZE_SECONDS
        mean_fr = bins_per_second * np.mean(spike_count[start_ind:end_ind])
        fr_per_trial.append(mean_fr)

    return fr_per_trial


def main():
    """Generate and save data."""
    # Load behavior data
    triangle_behavior = pd.read_csv(_BEHAVIOR_CACHE_PATH_TRIANGLE)
    ring_behavior = pd.read_csv(_BEHAVIOR_CACHE_PATH_RING)

    for subject_dir in sorted(_SPIKE_COUNTS_DATA_DIR.iterdir()):
        subject = subject_dir.name
        if subject.startswith("."):
            continue
        print(f"\nProcessing {subject}\n")
        for session_dir in sorted(subject_dir.iterdir()):
            session = session_dir.name
            if session.startswith("."):
                continue
            print(f"\nProcessing {session}\n")

            # Write dataframe
            write_path = _WRITE_DIR / subject / session / "fr.csv"
            if write_path.exists():
                print(f"Skipping {write_path} (already exists)")
                continue

            # Load behavior data for this session
            session_behavior_triangle = triangle_behavior[
                (triangle_behavior["subject"] == subject)
                & (triangle_behavior["session"] == session)
            ]
            session_behavior_ring = ring_behavior[
                (ring_behavior["subject"] == subject)
                & (ring_behavior["session"] == session)
            ]
            if len(session_behavior_triangle) > 0:
                print(f"Triangle data found")
                task = "triangle"
                session_behavior = session_behavior_triangle
            elif len(session_behavior_ring) > 0:
                print(f"Ring data found")
                task = "ring"
                session_behavior = session_behavior_ring
            else:
                raise ValueError("No behavior data found")

            # Make dataframe for this session
            session_df = {
                "task": [],
                "probe": [],
                "quality": [],
                "unit": [],
                "trial": [],
                "firing_rate": [],
            }
            # Iterate through units and get selectivity
            for probe_dir in sorted(session_dir.iterdir()):
                probe = probe_dir.name
                if probe.startswith("."):
                    continue
                print(f"\nProcessing {probe}\n")

                for quality_dir in sorted(probe_dir.iterdir()):
                    quality = quality_dir.name
                    if quality.startswith("."):
                        continue
                    print(f"\nProcessing {quality}\n")

                    num_units = len(list(quality_dir.iterdir())) // 2
                    unit_count = 0
                    for spike_counts_file in sorted(quality_dir.iterdir()):
                        if "spike_counts" not in spike_counts_file.name:
                            continue
                        trials_file = spike_counts_file.with_name(
                            spike_counts_file.name.replace(
                                "spike_counts", "trials"
                            )
                        )

                        if unit_count % 20 == 0:
                            print(
                                f"Processing unit {unit_count} / {num_units}"
                            )
                        unit_count += 1

                        # Load spike counts and trials
                        spike_counts = pickle.load(
                            open(spike_counts_file, "rb")
                        )
                        trials = pickle.load(open(trials_file, "rb"))

                        # Sanity check spike counts and trials have the same
                        # length
                        if len(spike_counts) != len(trials):
                            raise ValueError(
                                f"Length of spike_counts ({len(spike_counts)}) "
                                f"must match length of trials ({len(trials)})"
                            )

                        # Compute firing rates
                        fr = _get_firing_rates(
                            spike_counts,
                            trials,
                            session_behavior,
                        )

                        # Append to dataframe
                        num_trials = len(trials)
                        unit = spike_counts_file.name.split("_")[0]
                        session_df["task"].extend([task] * num_trials)
                        session_df["probe"].extend([probe] * num_trials)
                        session_df["quality"].extend([quality] * num_trials)
                        session_df["unit"].extend([unit] * num_trials)
                        session_df["trial"].extend(trials)
                        session_df["firing_rate"].extend(fr)

            # Convert to pandas dataframe
            session_df = pd.DataFrame(session_df)

            # Write dataframe
            write_path.parent.mkdir(parents=True, exist_ok=True)
            print(f"Writing to {write_path}")
            session_df.to_csv(write_path)


if __name__ == "__main__":
    main()
